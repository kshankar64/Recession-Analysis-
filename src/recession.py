# -*- coding: utf-8 -*-
"""Python Project 1225653286.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pti4G5sFOYA_25Gkp1p7Cun7_bytKTag
"""

import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
import time

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.svm import LinearSVC

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.model_selection import KFold
import warnings
warnings.filterwarnings("ignore")
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

def indentify_outliers (dataframe, fea_in):
    outliers = set()
    for i in fea_in:

        Q1 = np.percentile(dataframe[i], 25)
        Q3 = np.percentile(dataframe[i],75)
        IQR = Q3 - Q1

        upper_bound = list(np.where(dataframe[i] >= (Q3+1.5*IQR)))
        lower_bound = list(np.where(dataframe[i] <= (Q1-1.5*IQR)))

        for u in upper_bound:
            outliers.update(u)
        for l in lower_bound:
            outliers.update(l)
    return outliers

pd.set_option('display.max_rows', None)

data_read = pd.read_csv("C:\\Users\\kaush\\Downloads\\creditcard.csv")
data_read = data_read.drop(["Time"], axis = 1)

X = data_read.drop(["Class"], axis = 1)
y = data_read[["Class"]]
print("Number of features in the dataset:", X.shape[1])

sns.countplot(x = data_read["Class"])
plt.title("Class count of the dataset")

data_read.head(5)

print(data_read.isna().sum())

print("Number of data points of class 0:", sum(y["Class"] == 0))
print("Number of data points of class 1:", sum(y["Class"] == 1))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)
df_train = pd.concat([X_train, y_train], axis=1)
data_class0 = df_train[df_train["Class"] == 0]
data_class1 = df_train[df_train["Class"] == 1]
num_data_class1 = data_class1.shape[0]

print("Number of data points of class 0 in training dataset:", data_class0.shape[0])
print("Number of data points of class 1 in training dataset:", data_class1.shape[0])
print("Number of data points of class 0 in test dataset:", sum(y_test["Class"] == 0))
print("Number of data points of class 1 in test dataset:", sum(y_test["Class"] == 1))

correlation = data_read.corr()
correlation.head(5)

plt.figure(figsize=(10,8))
sns.heatmap(data_read.corr().drop(['Class'],axis=1), cmap='Blues', annot = False)

sorted_mat = data_read.corr().abs()[['Class']].sort_values('Class')
plt.figure(figsize=(5,10))
sns.heatmap(data_read.corr().abs()[['Class']].sort_values('Class'), cmap='Blues', annot = True)

data_class0_sampled_outliers = data_class0.sample(n = num_data_class1 * 20, replace = False, random_state = 1)

features_outliers = sorted_mat.index[0:10]
features_outliers = features_outliers.values.tolist()
print(features_outliers)

data_class0_copy = data_class0.reset_index()
outliers = indentify_outliers(data_class0_copy, features_outliers)
data_class0_copy.drop(outliers, inplace = True)
del data_class0_copy['index']
data_class0_sampled_no_outliers = data_class0_copy.sample(n = num_data_class1 * 20, replace = False, random_state = 1)

data_merged_outliers = pd.concat([data_class0_sampled_outliers, data_class1], axis=0)
data_merged_shuffled_outliers = data_merged_outliers.sample(random_state = 1, frac=1).reset_index(drop=True)

data_merged_no_outliers = pd.concat([data_class0_sampled_no_outliers, data_class1], axis=0)
data_merged_shuffled_no_outliers = data_merged_no_outliers.sample(random_state = 1, frac=1).reset_index(drop=True)

print("Number of data points of class 0 in downsampled training dataset:", data_class0_sampled_outliers.shape[0])
print("Number of data points of class 1 in downsampled training dataset:", data_class1.shape[0])

sns.countplot(x = data_merged_outliers["Class"])
plt.title("Class count of the dataset after downsampling")

fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(13,10))
fig.suptitle('Outliers not dropped Features vs Class', size = 20)
fig.tight_layout(pad=5.0)
sns.boxplot(ax=axes[0], data=data_class0, x='Class', y='V22', width=0.3)
axes[0].set_title("V22 distribution");
sns.boxplot(ax=axes[1], data=data_class0, x='Class', y='V23', width=0.3)
axes[1].set_title("V23 distribution");
sns.boxplot(ax=axes[2], data=data_class0, x='Class', y='V27', width=0.3)
axes[2].set_title("V27 distribution");
sns.boxplot(ax=axes[3], data=data_class0, x='Class', y='V28', width=0.3)
axes[3].set_title("V28 distribution");
plt.show()

fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(13,10))
fig.suptitle('Outliers dropped Features vs Class', size = 20)
fig.tight_layout(pad=5.0)
sns.boxplot(ax=axes[0], data=data_class0_copy, x='Class', y='V22', width=0.3)
axes[0].set_title("V1 distribution");
sns.boxplot(ax=axes[1], data=data_class0_copy, x='Class', y='V23', width=0.3)
axes[1].set_title("V2 distribution");
sns.boxplot(ax=axes[2], data=data_class0_copy, x='Class', y='V27', width=0.3)
axes[2].set_title("V27 distribution");
sns.boxplot(ax=axes[3], data=data_class0_copy, x='Class', y='V28', width=0.3)
axes[3].set_title("V28 distribution");
plt.show()

X_ds_outliers = data_merged_shuffled_outliers.drop(["Class"], axis = 1)
y_ds_outliers = data_merged_shuffled_outliers[["Class"]]

X_ds_no_outliers = data_merged_shuffled_no_outliers.drop(["Class"], axis = 1)
y_ds_no_outliers = data_merged_shuffled_no_outliers[["Class"]]

rs = preprocessing.RobustScaler()

X_train = rs.fit_transform(X_train)
y_train = y_train.to_numpy()

X_ds_outliers = rs.fit_transform(X_ds_outliers)
y_ds_outliers = y_ds_outliers.to_numpy()

X_ds_no_outliers = rs.fit_transform(X_ds_no_outliers)
y_ds_no_outliers = y_ds_no_outliers.to_numpy()

X_test = rs.fit_transform(X_test)
y_test = y_test.to_numpy()

cross_val_split = 5
k_value = 6
rnd_frst_est = 30
kf = KFold(n_splits = cross_val_split, shuffle=True, random_state = 1)

def train_model_no_cross_val(model, X_loop, y_loop):
    time_exe = []
    for model_loop in model:
        t_beg = time.time()
        model_loop.fit(X_loop, y_loop)
        t_end = time.time()
        time_exe.append(t_end-t_beg)
    return time_exe

knn_model0 = KNeighborsClassifier(n_neighbors=k_value, weights = 'distance')
random_frt_model0 = RandomForestClassifier(n_estimators = rnd_frst_est, random_state = 0)
decision_tree_model0= tree.DecisionTreeClassifier(random_state = 1)
logistic_model0 = LogisticRegression(penalty = 'l2', solver = 'liblinear',random_state = 1)

models_to_train0 = [knn_model0, random_frt_model0, logistic_model0, decision_tree_model0]# svc_model0]#, svm_model0]
models_comp_set_train_time = train_model_no_cross_val(models_to_train0, X_train, y_train)

def prediction_of_model(model, X_to_test, y_of_test):

    accuracy_list = []
    auc_score_list = []
    acc_class1_list = []
    acc_class0_list = []
    fpr_list = []
    tpr_list = []
    conf_mat = []

    for model_loop in model:
        y_pred = model_loop.predict(X_to_test)
        y_prob = model_loop.predict_proba(X_to_test)[:, 1]

        accuracy_list.append(accuracy_score(y_of_test, y_pred))
        auc_score_list.append(roc_auc_score(y_of_test, y_prob))
        fpr, tpr, _ = roc_curve(y_of_test, y_prob)

        cf = confusion_matrix(y_of_test, y_pred)
        acc_class1 = cf[1,1] / np.sum(cf[1,:])
        acc_class0 = cf[0,1] / np.sum(cf[0,:])

        conf_mat.append(cf)
        acc_class1_list.append(acc_class1)
        acc_class0_list.append(acc_class0)
        fpr_list.append(fpr)
        tpr_list.append(tpr)

    return ( accuracy_list, auc_score_list, acc_class1_list, acc_class0_list, conf_mat, fpr_list, tpr_list)

def train_model_cross_val(kf_used, models, X_loop, y_loop):
    time_exe = []
    for model_loop in models:
        fold = 0
        print("model being trained:", model_loop)
        t_beg = time.time()
        for train_index, val_index in kf.split(X_loop, y_loop):
            X_tr = X_loop[train_index]
            y_tr = y_loop[train_index]

            X_val = X_loop[val_index]
            y_val= y_loop[val_index]

            model_loop.fit(X_tr, y_tr)

            y_pred= model_loop.predict(X_val)
            y_prob = model_loop.predict_proba(X_val)[:, 1]
            accuracy = accuracy_score(y_val, y_pred)
            auc_score = roc_auc_score(y_val, y_prob)


            print(f"========== FOLD {fold} ==========")
            print("Accuracy of model:", accuracy)
            print("AUC score of model:", auc_score)

            fold += 1
        t_end = time.time()
        time_exe.append(t_end - t_beg)
        print(" ")
    return time_exe

def train_model_cross_val_svc(kf_used, model_loop, X_loop, y_loop):
    print("model being trained:", model_loop)
    t_beg = time.time()
    for train_index, val_index in kf.split(X_loop, y_loop):
        X_tr = X_loop[train_index]
        y_tr = y_loop[train_index]

        X_val = X_loop[val_index]
        y_val= y_loop[val_index]

        model_loop.fit(X_tr, y_tr)

        y_pred= model_loop.predict(X_val)
        y_prob = model_loop._predict_proba_lr(X_val)[:, 1]
        accuracy = accuracy_score(y_val, y_pred)
        auc_score = roc_auc_score(y_val, y_prob)


        print(f"========== FOLD {fold} ==========")
        print("Accuracy of model:", accuracy)
        print("AUC score of model:", auc_score)

        fold += 1
    return (t_end - t_beg)

# add one more model here
knn_model1 = KNeighborsClassifier(n_neighbors=k_value, weights = 'distance')
random_frt_model1 = RandomForestClassifier(n_estimators = rnd_frst_est, random_state = 0)
logistic_model1 = LogisticRegression(penalty  = 'l2', solver = 'liblinear', random_state = 1)
decision_tree_model1= tree.DecisionTreeClassifier(random_state = 1)
svc_model1 = SVC(C=2, gamma='auto', kernel='rbf', max_iter=71, probability = True, random_state = 1)
models_to_train1 = [knn_model1, random_frt_model1, logistic_model1, decision_tree_model1, svc_model1]
model_outliers_train_time = train_model_cross_val(kf, models_to_train1, X_ds_outliers, y_ds_outliers)

knn_model2 = KNeighborsClassifier(n_neighbors=k_value, weights = 'distance')
random_frt_model2 = RandomForestClassifier(n_estimators = rnd_frst_est, random_state = 0)
logistic_model2 = LogisticRegression(penalty = 'l2', solver = 'liblinear', random_state = 1)
decision_tree_model2= tree.DecisionTreeClassifier(random_state = 1)
svc_model2 = SVC(C=2, gamma='auto', kernel='rbf', max_iter=71, probability = True, random_state = 1)
models_to_train2 = [knn_model2, random_frt_model2, logistic_model2, decision_tree_model2, svc_model2]
model_no_outliers_train_time = train_model_cross_val(kf, models_to_train2, X_ds_no_outliers, y_ds_no_outliers)

results_comp_set = prediction_of_model(models_to_train0, X_test, y_test)

results_outliers = prediction_of_model(models_to_train1, X_test, y_test)
results_no_outliers = prediction_of_model(models_to_train2, X_test, y_test)

num_miss_pred_class0_comp_set = []
num_miss_pred_class1_comp_set = []
total_miss_pred_comp_set = []

num_miss_pred_class0_outliers = []
num_miss_pred_class1_outliers = []
total_miss_pred_outliers = []

num_miss_pred_class0_no_outliers = []
num_miss_pred_class1_no_outliers = []
total_miss_pred_no_outliers = []

for i in range(len(results_comp_set[4][:])):
    cf = results_comp_set[4][i]
    num_miss_pred_class0_comp_set.append(cf[0][1])
    num_miss_pred_class1_comp_set.append(cf[1][0])
    total_miss_pred_comp_set.append(cf[0][1]+cf[1][0])
for i in range(len(results_outliers[4][:])):
    cf = results_outliers[4][i]
    num_miss_pred_class0_outliers.append(cf[0][1])
    num_miss_pred_class1_outliers.append(cf[1][0])
    total_miss_pred_outliers.append(cf[0][1]+cf[1][0])
for i in range(len(results_no_outliers[4][:])):
    cf = results_no_outliers[4][i]
    num_miss_pred_class0_no_outliers.append(cf[0][1])
    num_miss_pred_class1_no_outliers.append(cf[1][0])
    total_miss_pred_no_outliers.append(cf[0][1]+cf[1][0])

# you will need to add your algo name here
algo_names = ["KNeighborsClassifier", "Random Forest", "Logistic Regression","Decision Tree","Support Vector Machine"]
parameters = ["Accuracy", "AUC_score", "TPR", "FPR","Training Time", "Num miss pred Class 0", "Num miss pred Class1", "Total miss pred"]
dataset_used = ["Entire train dataset", "Downsampled train dataset with outliers", "Downsampled train dataset without outliers"]

results_dict_comp_set = {'Model trained on': (dataset_used[0], dataset_used[0], dataset_used[0], dataset_used[0]),'Algorithm': algo_names[0:4],parameters[4]:models_comp_set_train_time, parameters[1]:results_comp_set[1],parameters[2]:results_comp_set[2], parameters[3]:results_comp_set[3], parameters[5]:num_miss_pred_class0_comp_set, parameters[6]:num_miss_pred_class1_comp_set, parameters[7]:total_miss_pred_comp_set}
results_dict_outliers = {'Model trained on': (dataset_used[1], dataset_used[1], dataset_used[1], dataset_used[1], dataset_used[1]),'Algorithm': algo_names, parameters[4]:model_outliers_train_time, parameters[1]:results_outliers[1],parameters[2]:results_outliers[2], parameters[3]:results_outliers[3], parameters[5]:num_miss_pred_class0_outliers, parameters[6]:num_miss_pred_class1_outliers, parameters[7]:total_miss_pred_outliers}
results_dict_no_outliers = {'Model trained on': (dataset_used[2], dataset_used[2], dataset_used[2], dataset_used[2], dataset_used[2]),'Algorithm': algo_names, parameters[4]:model_no_outliers_train_time, parameters[1]:results_no_outliers[1],parameters[2]:results_no_outliers[2], parameters[3]:results_no_outliers[3], parameters[5]:num_miss_pred_class0_no_outliers, parameters[6]:num_miss_pred_class1_no_outliers, parameters[7]:total_miss_pred_no_outliers}

pd_comp_set = pd.DataFrame(results_dict_comp_set)
pd_outliers = pd.DataFrame(results_dict_outliers)
pd_no_outliers = pd.DataFrame(results_dict_no_outliers)

results = pd.concat([pd_comp_set, pd_outliers, pd_no_outliers], ignore_index = True)

results

plt.plot(results_comp_set[5][0], results_comp_set[6][0], label='K Nearest Neighbors')
plt.plot(results_comp_set[5][1], results_comp_set[6][1], label='Random Forest')
plt.plot(results_comp_set[5][2], results_comp_set[6][2], label='Logistic Regression')
plt.plot(results_comp_set[5][3], results_comp_set[6][3], label='Decision Tree')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve for models trained on completed train dataset")
plt.legend()
plt.show()

plt.plot(results_outliers[5][0], results_outliers[6][0], label='K Nearest Neighbors')
plt.plot(results_outliers[5][1], results_outliers[6][1], label='Random Forest')
plt.plot(results_outliers[5][2], results_outliers[6][2], label='Logistic Regression')
plt.plot(results_outliers[5][3], results_outliers[6][3], label='Decision Tree')
plt.plot(results_outliers[5][4], results_outliers[6][4], label='Support Vector Machine')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve for models trained on downsampled dataset containing outliers")
plt.legend()
plt.show()

plt.plot(results_no_outliers[5][0], results_no_outliers[6][0], label='K Nearest Neighbors')
plt.plot(results_no_outliers[5][1], results_no_outliers[6][1], label='Random Forest')
plt.plot(results_no_outliers[5][2], results_no_outliers[6][2], label='Logistic Regression')
plt.plot(results_no_outliers[5][3], results_no_outliers[6][3], label='Decision Tree')
plt.plot(results_no_outliers[5][4], results_no_outliers[6][4], label='Support Vector Machine')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve for models trained on downsampled dataset not containing outliers")
plt.legend()
plt.show()

plt.plot(results_comp_set[5][0], results_comp_set[6][0], label='KNN trained on complete dataset')
plt.plot(results_outliers[5][0], results_outliers[6][0], label='KNN trained on downsampled with outliers')
plt.plot(results_no_outliers[5][0], results_no_outliers[6][0], label='KNN trained on downsampled with no outliers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve")
plt.legend()
plt.show()

plt.plot(results_comp_set[5][1], results_comp_set[6][1], label='Random Forest trained on complete dataset')
plt.plot(results_outliers[5][1], results_outliers[6][1], label='Random Forest trained on downsampled with outliers')
plt.plot(results_no_outliers[5][1], results_no_outliers[6][1], label='Random Forest trained on downsampled with no outliers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve")
plt.legend()
plt.show()

plt.plot(results_comp_set[5][2], results_comp_set[6][2], label='Logistic Regreesion trained on complete dataset')
plt.plot(results_outliers[5][2], results_outliers[6][2], label='Logistic Regreesion trained on downsampled with outliers')
plt.plot(results_no_outliers[5][2], results_no_outliers[6][2], label='Logistic Regreesion trained on downsampled with no outliers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve")
plt.legend()
plt.show()

plt.plot(results_comp_set[5][3], results_comp_set[6][3], label='Decision Tree trained on complete dataset')
plt.plot(results_outliers[5][3], results_outliers[6][3], label='Decision Tree trained on downsampled with outliers')
plt.plot(results_no_outliers[5][3], results_no_outliers[6][3], label='Decision Tree trained on downsampled with no outliers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve")
plt.legend()
plt.show()

plt.plot(results_outliers[5][4], results_outliers[6][4], label='SVM trained on downsampled with outliers')
plt.plot(results_no_outliers[5][4], results_no_outliers[6][4], label='SVM trained on downsampled with no outliers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("ROC Curve")
plt.legend()
plt.show()
